import numpy as np
from DiscreteD import DiscreteD
from GaussD import GaussD
from MarkovChain import MarkovChain


class HMM:
    """
    HMM - class for Hidden Markov Models, representing
    statistical properties of random sequences.
    Each sample in the sequence is a scalar or vector, with fixed DataSize.
    
    Several HMM objects may be collected in a single multidimensional array.
    
    A HMM represents a random sequence(X1,X2,....Xt,...),
    where each element Xt can be a scalar or column vector.
    The statistical dependence along the (time) sequence is described
    entirely by a discrete Markov chain.
    
    A HMM consists of two sub-objects:
    1: a State Sequence Generator of type MarkovChain
    2: an array of output probability distributions, one for each state
    
    All states must have the same class of output distribution,
    such as GaussD, GaussMixD, or DiscreteD, etc.,
    and the set of distributions is represented by an object array of that class,
    although this is NOT required by general HMM theory.
    
    All output distributions must have identical DataSize property values.
    
    Any HMM output sequence X(t) is determined by a hidden state sequence S(t)
    generated by an internal Markov chain.
    
    The array of output probability distributions, with one element for each state,
    determines the conditional probability (density) P[X(t) | S(t)].
    Given S(t), each X(t) is independent of all other X(:).
    
    
    References:
    Leijon, A. (20xx) Pattern Recognition. KTH, Stockholm.
    Rabiner, L. R. (1989) A tutorial on hidden Markov models
    	and selected applications in speech recognition.
    	Proc IEEE 77, 257-286.
    
    """
    def __init__(self, mc, distributions):

        self.stateGen = mc
        self.outputDistr = distributions

        self.nStates = mc.nStates
        self.dataSize = distributions[0].dataSize
    
    def rand(self, nSamples):
        """
        [X,S]=rand(self,nSamples); generates a random sequence of data
        from a given Hidden Markov Model.
        
        Input:
        nSamples=  maximum no of output samples (scalars or column vectors)
        
        Result:
        X= matrix or row vector with output data samples
        S= row vector with corresponding integer state values
          obtained from the self.StateGen component.
          nS= length(S) == size(X,2)= number of output samples.
          If the StateGen can generate infinite-duration sequences,
              nS == nSamples
          If the StateGen is a finite-duration MarkovChain,
              nS <= nSamples
        """
        
        #*** Insert your own code here and remove the following error message 
        S=self.stateGen.rand(nSamples);
        n_features=len(self.outputDistr[0].rand(1))
        nSamples_final=len(S[0,:]);
        X=np.empty((n_features,nSamples_final));
        for i in range(nSamples_final):
            s=S[0,i];
            if s<self.stateGen.nStates:
                X[:,i]=self.outputDistr[s].rand(1).ravel()
            else:
                X=X[:,:i]
        return X,S
        
    
    def forward(self,obs,norm=False):
        res, scaled = self.prob(obs);
        if not norm:
            scaled = res;
        self.res=res;self.scaled=scaled; #To avoid recalculations of this, which is expensive!
        return self.stateGen.forward(scaled)
    
    def backward(self, obs, scale = False):
        p, scaled =self.prob(obs);
        
        if not scale:
            scaled = p;
        self.res=p;self.scaled=scaled; #To avoid recalculations of this, which is expensive!
        
        return self.stateGen.backward(scaled)
    def viterbi(self):
        pass
    
    def calcabc(self, obs,scale=True):
        alphahats_list = []
        betahats_list = []
        cs_list = []
        self.res_list=[];self.scaled_list=[]
        for i in range(len(obs)):
            alphahats,betahats,cs = self.backward(obs[i],scale=scale)
            self.res_list.append(self.res);self.scaled_list.append(self.scaled);
            alphahats_list += [alphahats]
            betahats_list += [betahats]
            cs_list += [cs]
        return alphahats_list, betahats_list, cs_list
    
    def calcgammas(self, alphahats_list, betahats_list, cs_list, obs, uselog=True):
        gammas = []
        for i in range(len(obs)):
            temp = []
            for t in range(obs[i].shape[1]):
                if uselog:
                    temp += [np.log(alphahats_list[i][:,t])+np.log(betahats_list[i][:,t])+np.log(cs_list[i][t])]
                else:
                    temp += [alphahats_list[i][:,t]*betahats_list[i][:,t]*cs_list[i][t]]
            gammas += [np.array(temp)]
        #gammas = np.array(gammas)
        return gammas
    def calcinit(self, gammas, uselog=False):
        init_gamma=np.asarray([i[0,:] for i in gammas]);
        if uselog:
            return np.sum(np.exp(init_gamma), axis = 0)/np.sum(np.exp(init_gamma))
        else: 
            return np.sum(init_gamma, axis = 0)/np.sum(init_gamma)
        
    def calcxi(self, alphahats_list, betahats_list, cs_list, obs, uselog=False,scale=True):
        xirbars = []
        xirs = []
        for i in range(len(obs)): 
            if self.stateGen.is_finite:
                xi = np.zeros((obs[i].shape[1], self.stateGen.A.shape[0], self.stateGen.A.shape[1]))
            else:
                xi = np.zeros((obs[i].shape[1]-1, self.stateGen.A.shape[0], self.stateGen.A.shape[1]))
            
            if uselog: 
                xi = np.log(xi)
                p=np.log(self.res_list[i]);scaled=np.log(self.scaled_list[i])
                #p, scaled = np.log(self.prob(obs[i])) #Saved in the other variables because it was calculated before.
            else:
                p=self.res_list[i];scaled=self.scaled_list[i]
            pX=scaled if scale else p;
            for t in range(obs[i].shape[1]-1):
                for j in range(self.stateGen.A.shape[0]):
                    for k in range(self.stateGen.A.shape[0]):
                        if uselog:
                            xi[t, j, k] = np.log(alphahats_list[i][j][t])+np.log(self.stateGen.A[j,k])+pX[k][t+1]+np.log(betahats_list[i][k][t+1])
                        else:
                            xi[t, j, k] = alphahats_list[i][j][t]*self.stateGen.A[j,k]*pX[k][t+1]*betahats_list[i][k][t+1]
            if self.stateGen.is_finite:
                for j in range(self.stateGen.A.shape[0]):
                    if uselog:
                        xi[-1][j][-1] = np.log(alphahats_list[i][-1][j])+np.log(betahats_list[i][-1][j])+np.log(cs_list[i][-1])
                    else:
                        xi[-1][j][-1] = alphahats_list[i][-1][j]*betahats_list[i][-1][j]*cs_list[i][-1]
                
            if uselog:
                xi = np.exp(xi)
            xirs += [xi]
            xirbars += [np.sum(xi, axis = 0)]
            
        xibar = np.sum(xirbars, axis = 0)
        return xibar
    
    def calcmeansandcov(self,obs,gammas):
        summ = np.zeros((len(self.outputDistr), obs[0].shape[0]))
        sumc = np.zeros((len(self.outputDistr), obs[0].shape[0], obs[0].shape[0]))
        sumg = np.zeros((len(self.outputDistr)))

        for i in range(len(obs)):
            for t in range(obs[i].shape[1]): 
                for j in range(len(self.outputDistr)):
                    summ[j] += obs[i][:,t]*gammas[i][t][j]
                    sumg[j] += gammas[i][t][j]
                    temp = obs[i][:,t] - np.atleast_2d(self.outputDistr[j].means);
                    sumc[j] += gammas[i][t][j]*(temp.T.dot(temp))
                    
        newmean = np.zeros(summ.shape)
        newcov = np.zeros(sumc.shape)
        for i in range(newmean.shape[0]):
            if sumg[i] > 0:
                newmean[i] = summ[i]/sumg[i]
                newcov[i] = sumc[i]/sumg[i]
            else:
                newmean[i] = 0
                newcov[i]  = 0
        return newmean,newcov
    def baum_welch(self,obs,niter,uselog=True,history=True,scale=True):

        hist=[];
        for it in range(niter):
            alphahats_list, betahats_list, cs_list = self.calcabc(obs,scale=scale) #from Assignment 3 and 4
            gammas = self.calcgammas(alphahats_list, betahats_list, cs_list, obs, uselog) #alpha*beta*c
            newpi = self.calcinit(gammas, uselog) #average of gammas[:,0]
            xibar = self.calcxi(alphahats_list, betahats_list, cs_list, obs, uselog,scale=scale) #page 132
            if uselog: 
                xibar = np.exp(xibar)
                
            newA = np.array([i/np.sum(i) for i in xibar]) #xibar/sum_k(xibar); page 130
            
            if uselog: 
                gammas = [np.exp(i) for i in gammas]

            newmean,newcov = self.calcmeansandcov(obs,gammas)
            
            #update all variables
            self.stateGen.q = newpi
            self.stateGen.A = newA
            newoutputDistr = [GaussD( newmean[i], cov=newcov[i]) for i in range(len(self.outputDistr))]
            self.outputDistr = newoutputDistr
            if history:
                p_x_list=np.asarray([np.sum(np.log(i)) for i in cs_list]);
                hist.append(np.mean(np.exp(p_x_list)))
                #hist.append(np.median(p_x_list))
               # if np.median(p_x_list) > 0:
                 #   print("Weird!")
        return hist;

    def stateEntropyRate(self):
        pass

    def setStationary(self):
        pass

    def logprob(self,obs,norm=True):
        alphas, cs =self.forward(obs, norm=norm)
        return np.sum(np.log(cs))

    def adaptStart(self):
        pass

    def adaptSet(self):
        pass

    def adaptAccum(self):
        pass
    def prob(self, x):
        T = x.shape[1]
        N = len(self.outputDistr)
        res = np.zeros((N, T))
        
        for i in range(N):
            res[i,:] = self.outputDistr[i].prob(x[:,:].T).flatten()
        scaled = np.zeros(res.shape)
        for i in range(scaled.shape[0]):
            for j in range(scaled.shape[1]):
                scaled[i, j] = res[i,j]/np.amax(res[:,j])
        return res, scaled
    
def test_forward():
    u1=0;u2=3;std1=1;std2=2;
    mc = MarkovChain( np.array( [ 0.75, 0.25 ] ), np.array( [ [ 0.99, 0.01 ], [ 0.03, 0.97 ] ] ) ) 
    g1 = GaussD( means=[u1], stdevs=[std1] )   # Distribution for state = 1
    g2 = GaussD( means=[u2], stdevs=[std2] )   # Distribution for state = 2
    h  = HMM( mc, [g1, g2])                # The HMM
    x,s = h.rand(10)
    
    alphas,cs=h.forward(x);
    p1=np.prod(cs);
    
    #This checked that simple gaussian as emissor works too.
    
    ##Test of multiple gaussians:
    u1=0;u2=1;std1=1;std2=2;
    mc = MarkovChain( np.array( [ 0.75, 0.25 ] ), np.array( [ [ 0.99, 0.01 ], [ 0.03, 0.97 ] ] ) ) 
    g1 = GaussD( means=[u1, u1], cov=np.asarray([[2,1],[1,4]]) )   # Distribution for state = 1
    g2 = GaussD( means=[u2, u2], stdevs=np.asarray([[1,0],[0,1]]) )   # Distribution for state = 2
    h  = HMM( mc, [g1, g2])                # The HMM
    x,s = h.rand(5)
    
    alphas,cs=h.forward(x);
    p1=np.prod(cs);
    
    ##Now the test of the book 
    
    u1=0;u2=3;std1=1;std2=2;
    mc = MarkovChain( np.array( [ 1, 0 ] ), np.array( [ [ 0.9, 0.1,0 ], [ 0, 0.9, 0.1 ] ] ) ) 
    g1 = GaussD( means=[u1], stdevs=[std1] )   # Distribution for state = 1
    g2 = GaussD( means=[u2], stdevs=[std2] )   # Distribution for state = 2
    h  = HMM( mc, [g1, g2])                # The HMM
    
    x=np.array([[-0.2,2.6,1.3]])
    
    alphas,cs=h.forward(x,norm=True);
    print("For the example in the book:")
    print("The alphas matrix when normalized gave us:")
    print(alphas)
    print("And the Cs normalized:")
    print(cs)
    alphas,cs=h.forward(x,norm=False);
    print("And then when not normalized we get:")
    print(cs)
    print("Finally the logprob:")
    print(h.logprob(x,norm=False)) #Shows that it gets the value mentioned in the book
    
    
    ##To test that it works with discrete distributions we use excercise 5.2 from book. Also checking infinite HMM
    
    
    mc1 = MarkovChain( np.array( [ 0.5, 0.5 ] ), np.array( [ [ 0.2, 0.8 ], [ 0.8, 0.2 ] ] ) ) 
    mc2 = MarkovChain( np.array( [ 0.5, 0.5 ] ), np.array( [ [ 0.8, 0.2 ], [ 0.2, 0.8 ] ] ) ) 
    
    D1 = DiscreteD( [0.1,0.2,0.3,0.4] )   # Distribution for state = 1
    D2 = DiscreteD( [0.4,0.3,0.2,0.1] )   # Distribution for state = 2
    
    h1  = HMM( mc1, [D1, D2])
    h2  = HMM( mc2, [D1, D2])
    
    z=np.array([[3,1,4,2]])
    
    #In order for this one to work I had to:
        #Create prob function in discrete D.
        #Solved dimentions notations, sometimes it was called row when in our code was a column
    alphas_1,cs_1=h1.forward(z,norm=False);
    p1=np.prod(cs_1);
    alphas_2,cs_2=h2.forward(z,norm=False);
    p2=np.prod(cs_2);
    print("-------------------------------------------------------")
    print("To check that it works with discrete distributions and infinite HMM, we reproduced the problem 5.2 from the book and verified the results obtained: ")
    print("For lambda1 the book says that P=" + "0.005704" + " and the obtained probability is " + str(p1))
    print("For lambda2 the book says that P=" + "0.002824" + " and the obtained probability is " + str(p2))

def test_backward():
    u1=0;u2=3;std1=1;std2=2;
    mc = MarkovChain( np.array( [ 1, 0 ] ), np.array( [ [ 0.9, 0.1,0 ], [ 0, 0.9, 0.1 ] ] ) ) 
    g1 = GaussD( means=[u1], stdevs=[std1] )   # Distribution for state = 1
    g2 = GaussD( means=[u2], stdevs=[std2] )   # Distribution for state = 2
    h  = HMM( mc, [g1, g2])                # The HMM
    
    x=np.array([[-0.2,2.6,1.3]])
    #s=np.array([[1, 0.1625, 0.8266, 0.0581]])
    
    alphas,betas,cs=h.backward(x,scale=True);
    print("For the example in the book:")
    print("The betas matrix when normalized gave us:")
    print(betas)
def test_learning():
        # Define a HMM
    q = np.array([0.8, 0.2])
    A = np.array([[0.95, 0.05],
                  [0.30, 0.70]])
    
    means = np.array( [[0, 0], [2, 2]] )
    covs  = np.array( [[[1, 2],[2, 4]], 
                       [[1, 0],[0, 3]]] )
    mc = MarkovChain( q, A ) 
    g1 = GaussD( means=means[0], cov=covs[0] )   # Distribution for state = 1
    g2 = GaussD(means=means[1], cov=covs[1] )   # Distribution for state = 1
    
    hm  = HMM(mc,[g1,g2])
    #obs = np.array([ hm.rand(100)[0] for _ in range(10) ])
    
    print('True HMM parameters:')
    print('q:')
    print(q)
    print('A:')
    print(A)
    print('B: means, covariances')
    print(means)
    print(covs)
    obs_other_hmm=np.load("testobs.npy")
    obs=[i.T for i in obs_other_hmm]
    # Estimate the HMM parameters from the obseved samples
    # Start by. assigning initial HMM parameter values,
    # then refine these iteratively
    qstar = np.array([0.8, 0.2])
    Astar = np.array([[0.5, 0.5], [0.5, 0.5]])
    
    meansstar = np.array( [[0, 0], [2, 2]] )
    
    covsstar  = np.array( [[[1, 0],[0, 1]], 
                           [[1, 0],[0,1]]] )
    
    mc2 = MarkovChain( qstar, Astar ) 
    
    g1_2 = GaussD( means=meansstar[0], cov=covsstar[0] )   # Distribution for state = 1
    g2_2 = GaussD(means=meansstar[1], cov=covsstar[1] )   # Distribution for state = 1
    
    
    hm_learn  = HMM(mc2,[g1_2,g2_2])
    
    print("Running the Baum Welch Algorithm...")
    hist=hm_learn.baum_welch(obs, 20, uselog=False,scale=True)
    
    print('True HMM parameters:')
    print('q:')
    print(hm_learn.stateGen.q)
    print('A:')
    print(hm_learn.stateGen.A)
    print('B: means, covariances of 1')
    print(hm_learn.outputDistr[0].means)
    print(hm_learn.outputDistr[0].cov)
    print(hm_learn.outputDistr[1].means)
    print(hm_learn.outputDistr[1].cov)
    # hm_learn2 = HMM(mc2,[g1_2,g2_2])
    
    # print("Running the Baum Welch Algorithm with logs...")
    # hist=hm_learn2.baum_welch(obs, 6, uselog=True,scale=False)
    # print('True HMM parameters:')
    # print('q:')
    # print(hm_learn2.stateGen.q)
    # print('A:')
    # print(hm_learn2.stateGen.A)
    # print('B: means, covariances of 1')
    # print(hm_learn2.outputDistr[0].means)
    # print(hm_learn2.outputDistr[0].means)
if __name__ == "__main__":
    #test load and save of the model.
    #test_forward()
    #test_backward()
    test_learning();
    